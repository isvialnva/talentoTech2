{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Duver Ivan Lectamo\n",
        "Ejercicio\n",
        "Ejemplo de como implementar una red neuronal para clasificación con MLPClassifier utilizando Sklearn"
      ],
      "metadata": {
        "id": "ky_6AGyMgtI-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "69Nmmm4PgqRX"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conjunto de datos IRIS\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "lPlQEFuUhmcU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target"
      ],
      "metadata": {
        "id": "uouMYwM9hE2A"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explorando los datos\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "I7NKjjjAhi_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "type(iris)\n",
        "iris.keys\n",
        "iris['data']\n",
        "iris['target']\n",
        "iris['target_names']\n",
        "iris['DESCR']\n",
        "iris['feature_names']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypGhJfl7hLm4",
        "outputId": "67d9402d-dfe3-49c4-ec20-fe00c21ae00e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['sepal length (cm)',\n",
              " 'sepal width (cm)',\n",
              " 'petal length (cm)',\n",
              " 'petal width (cm)']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dividir lo datos en conjuntos de entrenamiento y prueba:\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "daBjvk7UhrZI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "TTQY9bErhg6s"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Escalar las caracteristicas para un mejor rendimiento del módelo\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "bMnfkcxjh4CE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "pa-rYOp1iAWp"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Crear la instancia d MLPClassifier\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "7KHzuIyah_ZC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp_clf = MLPClassifier(hidden_layer_sizes=(100),\n",
        "                        activation='relu',\n",
        "                        # activation='logistic',\n",
        "                        # activation='tanh',\n",
        "                        # solver='adam',\n",
        "                        solver='sgd',\n",
        "                        # solver='lbfgs',\n",
        "                        max_iter=200,\n",
        "                        learning_rate='adaptive',\n",
        "                        random_state=42,\n",
        "                        verbose=True)\n"
      ],
      "metadata": {
        "id": "GmYfoskEiN21"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entrenar el modelo\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "YZ-nPsQTilL7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp_clf.fit(X_train, y_train)\n",
        "y_pred = mlp_clf.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "FOwR_8xKinV4",
        "outputId": "315ab8f7-b291-4da3-95ac-c1ce4cf19215"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, loss = 1.18303736\n",
            "Iteration 2, loss = 1.16911075\n",
            "Iteration 3, loss = 1.15046646\n",
            "Iteration 4, loss = 1.12874134\n",
            "Iteration 5, loss = 1.10548714\n",
            "Iteration 6, loss = 1.08207828\n",
            "Iteration 7, loss = 1.05969661\n",
            "Iteration 8, loss = 1.03921764\n",
            "Iteration 9, loss = 1.02106330\n",
            "Iteration 10, loss = 1.00544543\n",
            "Iteration 11, loss = 0.99210574\n",
            "Iteration 12, loss = 0.98056096\n",
            "Iteration 13, loss = 0.97018037\n",
            "Iteration 14, loss = 0.96029527\n",
            "Iteration 15, loss = 0.95047132\n",
            "Iteration 16, loss = 0.94036702\n",
            "Iteration 17, loss = 0.92980922\n",
            "Iteration 18, loss = 0.91880221\n",
            "Iteration 19, loss = 0.90743423\n",
            "Iteration 20, loss = 0.89585446\n",
            "Iteration 21, loss = 0.88427196\n",
            "Iteration 22, loss = 0.87295847\n",
            "Iteration 23, loss = 0.86203142\n",
            "Iteration 24, loss = 0.85158784\n",
            "Iteration 25, loss = 0.84176612\n",
            "Iteration 26, loss = 0.83256316\n",
            "Iteration 27, loss = 0.82398454\n",
            "Iteration 28, loss = 0.81601465\n",
            "Iteration 29, loss = 0.80856900\n",
            "Iteration 30, loss = 0.80145858\n",
            "Iteration 31, loss = 0.79466570\n",
            "Iteration 32, loss = 0.78809498\n",
            "Iteration 33, loss = 0.78172732\n",
            "Iteration 34, loss = 0.77550335\n",
            "Iteration 35, loss = 0.76941975\n",
            "Iteration 36, loss = 0.76345794\n",
            "Iteration 37, loss = 0.75761550\n",
            "Iteration 38, loss = 0.75191654\n",
            "Iteration 39, loss = 0.74638913\n",
            "Iteration 40, loss = 0.74101877\n",
            "Iteration 41, loss = 0.73580645\n",
            "Iteration 42, loss = 0.73074026\n",
            "Iteration 43, loss = 0.72582523\n",
            "Iteration 44, loss = 0.72103979\n",
            "Iteration 45, loss = 0.71637244\n",
            "Iteration 46, loss = 0.71181469\n",
            "Iteration 47, loss = 0.70735248\n",
            "Iteration 48, loss = 0.70297192\n",
            "Iteration 49, loss = 0.69866720\n",
            "Iteration 50, loss = 0.69443517\n",
            "Iteration 51, loss = 0.69027282\n",
            "Iteration 52, loss = 0.68618174\n",
            "Iteration 53, loss = 0.68215462\n",
            "Iteration 54, loss = 0.67821066\n",
            "Iteration 55, loss = 0.67434282\n",
            "Iteration 56, loss = 0.67054532\n",
            "Iteration 57, loss = 0.66681733\n",
            "Iteration 58, loss = 0.66316552\n",
            "Iteration 59, loss = 0.65958589\n",
            "Iteration 60, loss = 0.65607670\n",
            "Iteration 61, loss = 0.65263579\n",
            "Iteration 62, loss = 0.64925452\n",
            "Iteration 63, loss = 0.64593588\n",
            "Iteration 64, loss = 0.64268022\n",
            "Iteration 65, loss = 0.63948571\n",
            "Iteration 66, loss = 0.63635211\n",
            "Iteration 67, loss = 0.63327842\n",
            "Iteration 68, loss = 0.63025480\n",
            "Iteration 69, loss = 0.62728165\n",
            "Iteration 70, loss = 0.62436070\n",
            "Iteration 71, loss = 0.62149259\n",
            "Iteration 72, loss = 0.61867524\n",
            "Iteration 73, loss = 0.61590757\n",
            "Iteration 74, loss = 0.61318721\n",
            "Iteration 75, loss = 0.61051248\n",
            "Iteration 76, loss = 0.60788065\n",
            "Iteration 77, loss = 0.60529191\n",
            "Iteration 78, loss = 0.60274590\n",
            "Iteration 79, loss = 0.60024087\n",
            "Iteration 80, loss = 0.59777714\n",
            "Iteration 81, loss = 0.59535234\n",
            "Iteration 82, loss = 0.59296603\n",
            "Iteration 83, loss = 0.59061692\n",
            "Iteration 84, loss = 0.58830330\n",
            "Iteration 85, loss = 0.58602469\n",
            "Iteration 86, loss = 0.58378027\n",
            "Iteration 87, loss = 0.58156855\n",
            "Iteration 88, loss = 0.57938875\n",
            "Iteration 89, loss = 0.57724031\n",
            "Iteration 90, loss = 0.57512295\n",
            "Iteration 91, loss = 0.57303595\n",
            "Iteration 92, loss = 0.57097772\n",
            "Iteration 93, loss = 0.56894760\n",
            "Iteration 94, loss = 0.56694514\n",
            "Iteration 95, loss = 0.56497022\n",
            "Iteration 96, loss = 0.56302191\n",
            "Iteration 97, loss = 0.56109905\n",
            "Iteration 98, loss = 0.55920117\n",
            "Iteration 99, loss = 0.55732749\n",
            "Iteration 100, loss = 0.55547744\n",
            "Iteration 101, loss = 0.55365151\n",
            "Iteration 102, loss = 0.55184804\n",
            "Iteration 103, loss = 0.55006683\n",
            "Iteration 104, loss = 0.54830684\n",
            "Iteration 105, loss = 0.54656773\n",
            "Iteration 106, loss = 0.54484904\n",
            "Iteration 107, loss = 0.54315031\n",
            "Iteration 108, loss = 0.54147117\n",
            "Iteration 109, loss = 0.53981115\n",
            "Iteration 110, loss = 0.53816978\n",
            "Iteration 111, loss = 0.53654665\n",
            "Iteration 112, loss = 0.53494137\n",
            "Iteration 113, loss = 0.53335351\n",
            "Iteration 114, loss = 0.53178293\n",
            "Iteration 115, loss = 0.53022899\n",
            "Iteration 116, loss = 0.52869166\n",
            "Iteration 117, loss = 0.52717067\n",
            "Iteration 118, loss = 0.52566536\n",
            "Iteration 119, loss = 0.52417537\n",
            "Iteration 120, loss = 0.52270043\n",
            "Iteration 121, loss = 0.52124010\n",
            "Iteration 122, loss = 0.51979415\n",
            "Iteration 123, loss = 0.51836229\n",
            "Iteration 124, loss = 0.51694418\n",
            "Iteration 125, loss = 0.51553976\n",
            "Iteration 126, loss = 0.51414854\n",
            "Iteration 127, loss = 0.51277010\n",
            "Iteration 128, loss = 0.51140448\n",
            "Iteration 129, loss = 0.51005119\n",
            "Iteration 130, loss = 0.50871001\n",
            "Iteration 131, loss = 0.50738084\n",
            "Iteration 132, loss = 0.50606328\n",
            "Iteration 133, loss = 0.50475772\n",
            "Iteration 134, loss = 0.50346328\n",
            "Iteration 135, loss = 0.50217996\n",
            "Iteration 136, loss = 0.50090738\n",
            "Iteration 137, loss = 0.49964548\n",
            "Iteration 138, loss = 0.49839407\n",
            "Iteration 139, loss = 0.49715275\n",
            "Iteration 140, loss = 0.49592166\n",
            "Iteration 141, loss = 0.49470031\n",
            "Iteration 142, loss = 0.49348870\n",
            "Iteration 143, loss = 0.49228671\n",
            "Iteration 144, loss = 0.49109393\n",
            "Iteration 145, loss = 0.48991050\n",
            "Iteration 146, loss = 0.48873608\n",
            "Iteration 147, loss = 0.48757056\n",
            "Iteration 148, loss = 0.48641394\n",
            "Iteration 149, loss = 0.48526579\n",
            "Iteration 150, loss = 0.48412609\n",
            "Iteration 151, loss = 0.48299451\n",
            "Iteration 152, loss = 0.48187117\n",
            "Iteration 153, loss = 0.48075573\n",
            "Iteration 154, loss = 0.47964813\n",
            "Iteration 155, loss = 0.47854833\n",
            "Iteration 156, loss = 0.47745604\n",
            "Iteration 157, loss = 0.47637127\n",
            "Iteration 158, loss = 0.47529379\n",
            "Iteration 159, loss = 0.47422357\n",
            "Iteration 160, loss = 0.47316038\n",
            "Iteration 161, loss = 0.47210429\n",
            "Iteration 162, loss = 0.47105495\n",
            "Iteration 163, loss = 0.47001244\n",
            "Iteration 164, loss = 0.46897704\n",
            "Iteration 165, loss = 0.46794868\n",
            "Iteration 166, loss = 0.46692715\n",
            "Iteration 167, loss = 0.46591208\n",
            "Iteration 168, loss = 0.46490315\n",
            "Iteration 169, loss = 0.46390043\n",
            "Iteration 170, loss = 0.46290373\n",
            "Iteration 171, loss = 0.46191298\n",
            "Iteration 172, loss = 0.46092813\n",
            "Iteration 173, loss = 0.45994897\n",
            "Iteration 174, loss = 0.45897561\n",
            "Iteration 175, loss = 0.45800775\n",
            "Iteration 176, loss = 0.45704549\n",
            "Iteration 177, loss = 0.45608860\n",
            "Iteration 178, loss = 0.45513712\n",
            "Iteration 179, loss = 0.45419085\n",
            "Iteration 180, loss = 0.45324989\n",
            "Iteration 181, loss = 0.45231398\n",
            "Iteration 182, loss = 0.45138319\n",
            "Iteration 183, loss = 0.45045733\n",
            "Iteration 184, loss = 0.44953640\n",
            "Iteration 185, loss = 0.44862031\n",
            "Iteration 186, loss = 0.44770896\n",
            "Iteration 187, loss = 0.44680242\n",
            "Iteration 188, loss = 0.44590042\n",
            "Iteration 189, loss = 0.44500316\n",
            "Iteration 190, loss = 0.44411037\n",
            "Iteration 191, loss = 0.44322208\n",
            "Iteration 192, loss = 0.44233811\n",
            "Iteration 193, loss = 0.44145866\n",
            "Iteration 194, loss = 0.44058347\n",
            "Iteration 195, loss = 0.43971256\n",
            "Iteration 196, loss = 0.43884595\n",
            "Iteration 197, loss = 0.43798352\n",
            "Iteration 198, loss = 0.43712526\n",
            "Iteration 199, loss = 0.43627141\n",
            "Iteration 200, loss = 0.43542145\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Realizar predicciones en el conjuntos de prueba\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "q01ATz0Ji_A6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = mlp_clf.predict(X_test_scaled)\n",
        "print(y_test)\n",
        "print(y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9mDdW-Zpi9kq",
        "outputId": "b1810e3e-95a6-4c06-bb08-efd0d8883f10"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0]\n",
            "[2 0 2 2 2 0 0 2 2 2 2 0 0 0 0 1 2 2 2 2 0 2 0 2 1 2 2 2 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calcular la precisión del modelo"
      ],
      "metadata": {
        "id": "CyrxoAofjUPE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Precisión del modelo: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5J83jQejYNx",
        "outputId": "30edc79b-1ade-4f07-ee84-c4a02aedf7b6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precisión del modelo: 0.7\n"
          ]
        }
      ]
    }
  ]
}